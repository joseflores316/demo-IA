# Default Configuration
# spring.profiles.active=dev  # Comentado para usar configuraciÃ³n por defecto en Docker

# Server Configuration
server.port=8080

# Database Configuration (PostgreSQL for Docker, H2 for local development)
spring.datasource.url=${SPRING_DATASOURCE_URL:jdbc:h2:mem:testdb}
spring.datasource.driverClassName=${SPRING_DATASOURCE_DRIVER:org.h2.Driver}
spring.datasource.username=${SPRING_DATASOURCE_USERNAME:sa}
spring.datasource.password=${SPRING_DATASOURCE_PASSWORD:password}

# JPA/Hibernate Configuration
spring.jpa.database-platform=${HIBERNATE_DIALECT:org.hibernate.dialect.H2Dialect}
spring.jpa.hibernate.ddl-auto=${HIBERNATE_DDL_AUTO:create-drop}
spring.jpa.show-sql=true

# File Upload Configuration
spring.servlet.multipart.enabled=true
spring.servlet.multipart.max-file-size=5MB
spring.servlet.multipart.max-request-size=5MB

# File Storage Configuration
app.upload.dir=/app/uploads
app.base.url=http://localhost:8080

# SpringDoc OpenAPI Configuration
springdoc.api-docs.enabled=true
springdoc.swagger-ui.enabled=true
springdoc.swagger-ui.path=/swagger-ui.html
springdoc.api-docs.path=/v3/api-docs

# Cloudinary Configuration
cloudinary.cloud-name=${CLOUDINARY_CLOUD_NAME:your-cloud-name}
cloudinary.api-key=${CLOUDINARY_API_KEY:your-api-key}
cloudinary.api-secret=${CLOUDINARY_API_SECRET:your-api-secret}

# Cache Configuration
spring.cache.type=caffeine
spring.cache.caffeine.spec=maximumSize=300,expireAfterAccess=20m,expireAfterWrite=1h

# Cache especÃ­fico para cada entidad (sin paÃ­ses)
app.cache.actrices.max-size=100
app.cache.actrices.expire-after-access=15m
app.cache.escenas.max-size=150
app.cache.escenas.expire-after-access=30m

# Actuator Endpoints Configuration
management.endpoints.web.exposure.include=health,info,metrics,env,caches
management.endpoint.health.show-details=always
management.metrics.export.prometheus.enabled=true

# ConfiguraciÃ³n de Kafka - TODOS LOS EVENTOS
spring.kafka.bootstrap-servers=${SPRING_KAFKA_BOOTSTRAP_SERVERS:kafka:29092}
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.producer.properties.spring.json.type.mapping=actrizCreadaEvent:com.jose.demoia.actriz.infrastructure.messaging.events.ActrizCreadaEvent,actrizActualizadaEvent:com.jose.demoia.actriz.infrastructure.messaging.events.ActrizActualizadaEvent,actrizEliminadaEvent:com.jose.demoia.actriz.infrastructure.messaging.events.ActrizEliminadaEvent
spring.kafka.consumer.group-id=actriz-events-group
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.type.mapping=actrizCreadaEvent:com.jose.demoia.actriz.infrastructure.messaging.events.ActrizCreadaEvent,actrizActualizadaEvent:com.jose.demoia.actriz.infrastructure.messaging.events.ActrizActualizadaEvent,actrizEliminadaEvent:com.jose.demoia.actriz.infrastructure.messaging.events.ActrizEliminadaEvent
spring.kafka.consumer.properties.spring.json.trusted.packages=com.jose.demoia.actriz.infrastructure.messaging.events
spring.kafka.consumer.auto-offset-reset=earliest

# Logging Configuration para Kafka - NIVEL MAS BAJO
logging.level.root=INFO
logging.level.com.jose.demoia=DEBUG
logging.level.com.jose.demoia.actriz.infrastructure.messaging=TRACE
logging.level.org.springframework.kafka=DEBUG
logging.level.org.apache.kafka=DEBUG
logging.level.kafka=DEBUG
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n

# Production Configuration for Railway
spring.datasource.url=${JDBC_DATABASE_URL:jdbc:postgresql://localhost:5432/actriz_db}
spring.datasource.username=${PGUSER:postgres}
spring.datasource.password=${PGPASSWORD:postgres}
spring.datasource.driver-class-name=org.postgresql.Driver

# JPA/Hibernate Configuration
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.format_sql=false

# Optimizacion de conexiones para reducir memoria
spring.datasource.hikari.maximum-pool-size=5
spring.datasource.hikari.minimum-idle=2
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.idle-timeout=600000
spring.datasource.hikari.max-lifetime=1800000

# Server Configuration
server.port=${PORT:8080}
# Optimizacion del servidor
server.tomcat.max-threads=50
server.tomcat.min-spare-threads=10

# File Upload Configuration
spring.servlet.multipart.enabled=true
spring.servlet.multipart.max-file-size=5MB
spring.servlet.multipart.max-request-size=5MB

# File Storage Configuration for Railway
app.upload.dir=${RAILWAY_VOLUME_MOUNT_PATH:/app/uploads}
app.base.url=https://${RAILWAY_PUBLIC_DOMAIN:demo-ia-production.up.railway.app}

# Cloudinary Configuration
cloudinary.cloud-name=${CLOUDINARY_CLOUD_NAME:}
cloudinary.api-key=${CLOUDINARY_API_KEY:}
cloudinary.api-secret=${CLOUDINARY_API_SECRET:}

# Kafka Configuration for Railway - CONFLUENT CLOUD - CONFIGURACION ROBUSTA
spring.kafka.enabled=${KAFKA_ENABLED:false}
spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}

# Configuracion SASL/SSL para Confluent Cloud - CORREGIDA
spring.kafka.properties.security.protocol=${KAFKA_SECURITY_PROTOCOL:SASL_SSL}
spring.kafka.properties.sasl.mechanism=${KAFKA_SASL_MECHANISM:PLAIN}
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_USERNAME:}" password="${KAFKA_PASSWORD:}";

# Configuraciones SSL mas permisivas para Confluent Cloud
spring.kafka.properties.ssl.endpoint.identification.algorithm=
spring.kafka.properties.ssl.truststore.type=JKS
spring.kafka.properties.ssl.check.hostname=false
spring.kafka.properties.ssl.truststore.location=
spring.kafka.properties.ssl.truststore.password=

# Configuraciones de conexion mas robustas
spring.kafka.properties.session.timeout.ms=30000
spring.kafka.properties.heartbeat.interval.ms=10000
spring.kafka.properties.request.timeout.ms=120000
spring.kafka.properties.retry.backoff.ms=1000
spring.kafka.properties.reconnect.backoff.ms=2000
spring.kafka.properties.reconnect.backoff.max.ms=64000
spring.kafka.properties.connections.max.idle.ms=540000

# Producer Configuration para Confluent Cloud - MAS ROBUSTO
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.producer.acks=1
spring.kafka.producer.retries=5
spring.kafka.producer.retry.backoff.ms=1000
spring.kafka.producer.request.timeout.ms=120000
spring.kafka.producer.delivery.timeout.ms=300000
spring.kafka.producer.properties.max.in.flight.requests.per.connection=1
spring.kafka.producer.properties.enable.idempotence=true
spring.kafka.producer.properties.spring.json.type.mapping=actrizCreadaEvent:com.jose.demoia.actriz.infrastructure.messaging.events.ActrizCreadaEvent,actrizActualizadaEvent:com.jose.demoia.actriz.infrastructure.messaging.events.ActrizActualizadaEvent,actrizEliminadaEvent:com.jose.demoia.actriz.infrastructure.messaging.events.ActrizEliminadaEvent

# Consumer Configuration para Confluent Cloud - SIMPLIFICADO PARA EVITAR ERRORES
spring.kafka.consumer.group-id=actriz-events-group
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=5000
spring.kafka.consumer.session.timeout.ms=30000
spring.kafka.consumer.heartbeat.interval.ms=10000
spring.kafka.consumer.max.poll.interval.ms=600000
spring.kafka.consumer.request.timeout.ms=120000
spring.kafka.consumer.fetch.min.bytes=1
spring.kafka.consumer.fetch.max.wait.ms=500

# Configuraciones especificas para evitar fallos en startup
spring.kafka.consumer.properties.bootstrap.servers=${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
spring.kafka.consumer.properties.retry.backoff.ms=2000
spring.kafka.consumer.properties.reconnect.backoff.ms=5000
spring.kafka.consumer.properties.reconnect.backoff.max.ms=120000
spring.kafka.consumer.properties.connections.max.idle.ms=900000

# Configuracion de container para manejo de errores en startup - SIMPLIFICADO
spring.kafka.listener.ack-mode=manual_immediate
spring.kafka.listener.client-id=actriz-consumer
spring.kafka.listener.concurrency=1
spring.kafka.listener.poll-timeout=3000
spring.kafka.listener.type=single
spring.kafka.listener.missing-topics-fatal=false

# Cache Configuration
spring.cache.type=caffeine
spring.cache.caffeine.spec=maximumSize=300,expireAfterAccess=20m,expireAfterWrite=1h

# Cache especifico para cada entidad
app.cache.actrices.max-size=100
app.cache.actrices.expire-after-access=15m
app.cache.escenas.max-size=150
app.cache.escenas.expire-after-access=30m

# CORS Configuration
app.cors.allowed-origins=${CORS_ALLOWED_ORIGINS:https://loving-exploration-production.up.railway.app,https://anpau.es,https://www.anpau.es}

# SpringDoc OpenAPI Configuration
springdoc.api-docs.enabled=true
springdoc.swagger-ui.enabled=true
springdoc.swagger-ui.path=/swagger-ui.html
springdoc.api-docs.path=/v3/api-docs

# Optimizacion de memoria para JPA
spring.jpa.properties.hibernate.jdbc.batch_size=20
spring.jpa.properties.hibernate.cache.use_second_level_cache=false
spring.jpa.properties.hibernate.cache.use_query_cache=false

# Observabilidad y Monitoreo - Spring Boot Actuator
management.endpoints.web.exposure.include=health,info,metrics,prometheus,env,loggers,caches
management.endpoint.health.show-details=always
management.health.db.enabled=true
management.health.diskspace.enabled=true

# Metricas y monitoring
management.metrics.export.prometheus.enabled=true
management.metrics.distribution.percentiles-histogram.http.server.requests=true
management.metrics.distribution.percentiles.http.server.requests=0.5,0.95,0.99

# Logging configuration optimizado
logging.level.root=INFO
logging.level.com.jose.demoia=INFO
logging.level.com.jose.demoia.actriz.infrastructure.messaging=INFO
logging.level.org.springframework.web=WARN
logging.level.org.hibernate=WARN
logging.level.com.zaxxer.hikari=WARN
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n
logging.pattern.file=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n

# Application info for actuator
info.app.name=Demo IA Application
info.app.description=Sistema de gestion de actrices y escenas
info.app.version=1.0.0
info.app.encoding=UTF-8
info.app.java.version=11
